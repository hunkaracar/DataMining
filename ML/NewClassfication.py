import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier  # ğŸ’¡ Eklendi
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import learning_curve

# 1. ğŸ“ Veri setinin yolu
file_path = 'Global_Cybersecurity_Threats_2015-2024.csv'

# 2. ğŸ“Š Veri setini oku
df = pd.read_csv(file_path)

# 3. ğŸ¯ Hedef deÄŸiÅŸken
y = df['Target Industry']  # Hangi sektÃ¶re saldÄ±rÄ±ldÄ±ÄŸÄ± tahmin edilecek
# Target Industry â†’ KNN 0.968
# Attack Type --> KNN 0.8456
# Security Vulnerability Type --> KNN 0.862333
print(f"Class count: {y.nunique()}")


# 4. ğŸ”¢ Kategorik verileri sayÄ±sala Ã§evir (One-Hot Encoding)
df_encoded = pd.get_dummies(df.drop(['Financial Loss (in Million $)'], axis=1))

# 5. âœ… Ã–zellik matrisi (X)
X = df_encoded

# 6. ğŸ”§ Veriyi Ã¶lÃ§eklendir (standartlaÅŸtÄ±r)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 7. ğŸ” Stratified K-Fold Ã§apraz doÄŸrulama
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# StratifiedKFold â†’ veriyi 5 parÃ§aya bÃ¶ler, her parÃ§ada sÄ±nÄ±f oranlarÄ±nÄ± (label distribution) korur.

# 8. ğŸ¤– KullanÄ±lacak modeller
models = {
    "KNN (k=5)": KNeighborsClassifier(n_neighbors=5),
    "SVC (linear)": SVC(kernel='linear', probability=True),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42), 
}


# 9. ğŸ“ˆ SonuÃ§larÄ± kaydetmek iÃ§in liste
results = []

# 10. ğŸ” Her model iÃ§in deÄŸerlendirme
for name, model in models.items():
    print(f"\nModel: {name}")
    
    # ğŸ”„ K-Fold doÄŸrulama tahminleri
    y_pred = cross_val_predict(model, X_scaled, y, cv=kfold)
    # model: eÄŸitim + tahmin burada yapÄ±lÄ±r, 5 farklÄ± parÃ§anÄ±n her birinde
    # Her parÃ§a sÄ±rayla test seti olur, diÄŸerleri eÄŸitim seti
    # cross_val_predict â†’ tÃ¼m veri iÃ§in tahminleri dÃ¶ndÃ¼rÃ¼r (Ã§apraz doÄŸrulama iÃ§inde)

    # ğŸ¯ DeÄŸerlendirme metrikleri
    acc = accuracy_score(y, y_pred)
    prec = precision_score(y, y_pred, average='weighted', zero_division=0)
    rec = recall_score(y, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y, y_pred, average='weighted', zero_division=0)

    # ğŸ–¨ï¸ Metrik Ã§Ä±ktÄ±larÄ±
    print("Accuracy :", f"{acc:.4f}")
    print("Precision:", f"{prec:.4f}")
    print("Recall   :", f"{rec:.4f}")
    print("F1-score :", f"{f1:.4f}")

    # ğŸ“ SÄ±nÄ±flandÄ±rma raporu
    print("\nClassification Report:\n", classification_report(y, y_pred, zero_division=0))

    # ğŸ“Š Confusion matrix
    cm = confusion_matrix(y, y_pred)
    plt.figure(figsize=(8, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.show()

    # ğŸ“‹ SonuÃ§larÄ± tabloya ekle
    results.append({
        "Model": name,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1-Score": f1
    })


def plot_learning_curve(estimator, title, X, y, cv, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)):
    """
    Verilen model iÃ§in Ã¶ÄŸrenme eÄŸrisi Ã§izer.
    """
    plt.figure(figsize=(8, 5))
    plt.title(title)
    plt.xlabel("Training Sample Size")
    plt.ylabel(scoring.capitalize())
    
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, scoring=scoring, n_jobs=n_jobs, train_sizes=train_sizes
    )
    
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std  = np.std(train_scores, axis=1)
    test_scores_mean  = np.mean(test_scores, axis=1)
    test_scores_std   = np.std(test_scores, axis=1)
    
    plt.grid(True)

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")

    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Train Score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Validation Score")

    plt.legend(loc="best")
    plt.tight_layout()
    plt.show()

# Ã–ÄŸrenme eÄŸrisi - Random Forest
plot_learning_curve(RandomForestClassifier(n_estimators=100, random_state=42),
                    "Learning Curve - Random Forest", X_scaled, y, cv=kfold, scoring='f1_weighted')

# Ã–ÄŸrenme eÄŸrisi - SVC
plot_learning_curve(SVC(kernel='linear', probability=True),
                    "Learning Curve - SVC (linear)", X_scaled, y, cv=kfold, scoring='f1_weighted')

# Ã–ÄŸrenme eÄŸrisi - SVC
plot_learning_curve(KNeighborsClassifier(n_neighbors=5),
                    "Learning Curve - KNN", X_scaled, y, cv=kfold, scoring='f1_weighted')


# Ã¼Ã§ model iÃ§in accuracy grafiÄŸi
results_df = pd.DataFrame(results)
plt.figure(figsize=(10, 6))
sns.barplot(x='Model', y='Accuracy', data=results_df, palette='viridis')
plt.title('Model Accuracy Comparison')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
# SonuÃ§larÄ± tabloya yazdÄ±r
print("\nSonuÃ§lar:")
print(results_df)
# En iyi model
best_model = results_df.loc[results_df['Accuracy'].idxmax()]
print("\nEn iyi model:")
print(best_model)
# En iyi modelin detaylarÄ±

# âœ… En iyi modeli tekrar tanÄ±mla ve eÄŸit
#best_clf = KNeighborsClassifier(n_neighbors=5)
best_clf = SVC(kernel='linear')
best_clf.fit(X_scaled, y)

# ğŸ” KullanÄ±cÄ±dan test verisi almak iÃ§in Ã¶rnek veri tanÄ±mÄ±
# Bu veri, orijinal veri setindeki sÃ¼tunlarla uyumlu olmalÄ±dÄ±r.
# Ã–rnek: bir siber saldÄ±rÄ±nÄ±n detaylarÄ±nÄ± simÃ¼le ediyoruz.
# Not: GerÃ§ek kullanÄ±mda bu veriyi formdan veya sistemden alabilirsin.

"""
test_data_dict = {
    'Year': 2024,
    'Country': 'USA',
    'Attack Type': 'Phishing',
    'Security Vulnerability Type': 'Email Spoofing',
    'Severity': 'High',
    'Attack Vector': 'Email',
    'Threat Actor Type': 'Criminal Group',
    'Record Count Leaked': 120000,
    'Detection Method': 'Anomaly Detection',
    'Target Industry': 'Unknown'  # Bu sadece y'de olduÄŸu iÃ§in Ã§Ä±karÄ±labilir
}

"""
test_data_dict = {
    'Year': 2021,
    'Country': 'India',
    'Attack Type': 'SQL Injection',
    'Security Vulnerability Type': 'Input Validation Failure',
    'Severity': 'Medium',
    'Attack Vector': 'Web',
    'Threat Actor Type': 'Hacktivist',
    'Record Count Leaked': 10000,
    'Detection Method': 'Manual Review',
    'Target Industry': 'Unknown'
}

# ğŸ”§ Test verisini DataFrame'e Ã§evir
test_df = pd.DataFrame([test_data_dict])

# ğŸ”¢ One-Hot Encoding iÅŸlemi (eÄŸitimdeki sÃ¼tunlarla uyum saÄŸlamak iÃ§in)
test_encoded = pd.get_dummies(test_df.drop(['Target Industry'], axis=1))

# ğŸ§© Eksik sÃ¼tunlarÄ± tamamlama (eÄŸitimdeki ile uyumsuzluk varsa)
for col in df_encoded.columns:
    if col not in test_encoded.columns:
        test_encoded[col] = 0

# âœ… SÃ¼tun sÄ±rasÄ±nÄ± aynÄ± hale getir
test_encoded = test_encoded[df_encoded.columns]

# ğŸ”§ Test verisini Ã¶lÃ§eklendir
test_scaled = scaler.transform(test_encoded)

# ğŸ”® Tahmin et
predicted_sector = best_clf.predict(test_scaled)[0]

# ğŸ–¨ï¸ Sonucu gÃ¶ster
print("\nğŸ” Tahmin edilen hedef sektÃ¶r:")
print(predicted_sector)
